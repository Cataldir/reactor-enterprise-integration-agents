# ğŸ¬ Pattern 2: Pipes and Filters with Cognitive Capabilities

## ğŸ“º YouTube Presentation Style

What's up, cloud architects! ğŸš€ Today we're exploring one of the COOLEST enterprise integration patterns - **Pipes and Filters with AI superpowers**!

## ğŸ¯ What's This Pattern About?

Think of it like an **assembly line for data**, but instead of robots, we have **AI agents** at each station! Each agent:
- ğŸ” **Analyzes** the data
- ğŸ¨ **Transforms** it intelligently  
- ğŸ¯ **Passes** it to the next agent
- ğŸ§  **Learns** from context

## ğŸ—ï¸ Architecture Overview

```
Input Data
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Filter 1       â”‚
â”‚  (AI Agent)     â”‚â”€â”€â–º Sentiment Analysis
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Filter 2       â”‚
â”‚  (AI Agent)     â”‚â”€â”€â–º Entity Extraction
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Filter 3       â”‚
â”‚  (AI Agent)     â”‚â”€â”€â–º Summarization
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
    Output Data
```

### ğŸŒŸ Parallel Pipeline Option

```
                     â”Œâ”€â–º Filter A (Sentiment) â”€â”€â”
                     â”‚                           â”‚
Input Data â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â–º Filter B (Topics) â”€â”€â”€â”€â”€â”¼â”€â”€â–º All Results
                     â”‚                           â”‚
                     â””â”€â–º Filter C (Language) â”€â”€â”€â”€â”˜
```

## ğŸ”¥ The Enterprise Integration Pattern

**Pipes and Filters** is a classic pattern where:

1. **Filters** - Independent processing units (our AI agents!)
2. **Pipes** - Data flow channels between filters
3. **Sequential** - Process one after another
4. **Parallel** - Process simultaneously for speed

### Why AI-Powered Filters Rock! ğŸ¸

- âœ… **Context-Aware** - Agents understand what they're processing
- âœ… **Flexible** - Easy to add/remove/reorder filters
- âœ… **Scalable** - Each filter can scale independently
- âœ… **Reusable** - Filters can be used in multiple pipelines
- âœ… **Maintainable** - Change one filter without affecting others

## ğŸ› ï¸ Technologies Used

- **Azure AI Foundry Agents** - Each filter is an AI agent ğŸ¤–
- **FastAPI** - REST API for pipeline execution ğŸš€
- **Async Python** - Non-blocking, concurrent processing âš¡
- **MCP Layer** - Standardized communication protocol ğŸ”—
- **Pydantic** - Data validation and serialization âœ…

## ğŸš€ Quick Start

### Prerequisites

1. Azure AI Foundry project configured
2. Python 3.11+
3. Environment variables set

### Setup

1. **Navigate to pattern:**
```bash
cd pattern-2-pipes-filters
```

2. **Configure environment:**
```bash
cp ../.env.example .env
# Edit with your credentials
```

3. **Install dependencies:**
```bash
pip install -r ../requirements.txt
```

### ğŸƒ Running the Application

**Option 1: Demo Script**
```bash
python main.py
```

**Option 2: REST API**
```bash
python api.py
# OR
uvicorn api:app --port 8001 --reload
```

### ğŸ³ Docker Deployment

**Build:**
```bash
# Production
docker build -t pipes-filters-agent --target production .

# Development
docker build -t pipes-filters-agent-dev --target development .
```

**Run:**
```bash
# Production
docker run --env-file .env pipes-filters-agent

# Development with hot reload
docker run -p 8001:8001 -v $(pwd):/app/pattern-2-pipes-filters --env-file .env pipes-filters-agent-dev
```

## ğŸ“¡ API Endpoints

### Execute Custom Pipeline
```bash
POST /pipeline/execute
{
  "input_data": "Your text here...",
  "filters": [
    {
      "name": "Sentiment Analyzer",
      "instructions": "Analyze sentiment..."
    },
    {
      "name": "Entity Extractor",
      "instructions": "Extract entities..."
    }
  ],
  "parallel": false
}
```

### Preset: Text Analysis Pipeline
```bash
POST /pipeline/preset/text-analysis
{
  "input_text": "Microsoft announced Azure AI Foundry today..."
}
```

### Preset: Parallel Analysis
```bash
POST /pipeline/preset/parallel-analysis
{
  "input_text": "Your text for parallel processing..."
}
```

### Health Check
```bash
GET /health
```

## ğŸ’¡ How It Works

### Sequential Pipeline

1. **Input** enters the pipeline
2. **Filter 1** processes and transforms
3. **Filter 2** receives Filter 1's output
4. **Filter 3** receives Filter 2's output
5. **Final output** is returned

Each filter adds value and context!

### Parallel Pipeline

1. **Input** is copied to all filters
2. **All filters** process simultaneously
3. **Results** are collected together
4. **All outputs** returned as array

Perfect for independent analyses!

## ğŸ“ Key Concepts

### CognitiveFilter Class
Each filter is an AI agent that:
- Has specific instructions
- Maintains conversation context
- Processes data intelligently
- Records transformations

```python
filter = CognitiveFilter(
    name="Sentiment Analyzer",
    project_client=client,
    agent_id=agent_id,
    instructions="Analyze sentiment..."
)
```

### Pipeline Composition
Build pipelines fluently:
```python
pipeline = Pipeline("My Pipeline")
    .add_filter(filter1)
    .add_filter(filter2)
    .add_filter(filter3)

result = await pipeline.execute(data)
```

### PipelineData
Carries information through the pipeline:
- **content** - The actual data
- **metadata** - Processing information
- **transformations** - Audit trail

## ğŸ“Š Real-World Use Cases

Perfect for:

1. ğŸ“„ **Document Processing**
   - Extract â†’ Classify â†’ Summarize â†’ Store

2. ğŸ“§ **Email Processing**
   - Parse â†’ Sentiment â†’ Priority â†’ Route

3. ğŸ¥ **Content Moderation**
   - Detect â†’ Analyze â†’ Score â†’ Action

4. ğŸ“Š **Data Enrichment**
   - Clean â†’ Validate â†’ Enhance â†’ Format

5. ğŸ” **Log Analysis**
   - Parse â†’ Detect Patterns â†’ Alert â†’ Archive

## ğŸ¯ Advanced Features

### Custom Filter Instructions
Tailor each filter's behavior:
```python
FilterConfig(
    name="Custom Analyzer",
    instructions="""
    You are an expert analyzer.
    Focus on: X, Y, Z
    Output format: JSON
    """
)
```

### Error Handling
Pipelines continue even if a filter fails:
- Failed filters are logged
- Metadata tracks status
- Downstream filters get last good output

### Performance Optimization
- Use parallel pipelines for independent tasks
- Reuse agent threads for multiple runs
- Async execution throughout

## ğŸ” Best Practices

1. âœ… **Single Responsibility** - Each filter does ONE thing well
2. âœ… **Stateless Filters** - Don't depend on previous runs
3. âœ… **Clear Instructions** - Be specific with agent instructions
4. âœ… **Error Handling** - Always check filter status
5. âœ… **Logging** - Track transformations for debugging

## ğŸ“ˆ Monitoring

Track pipeline health:
- Execution time per filter
- Success/failure rates
- Transformation audit trail
- Agent performance metrics

```python
print(f"Transformations: {result.transformations}")
print(f"Metadata: {result.metadata}")
```

## ğŸ¬ Coming Up Next!

In the next patterns:
- **Pattern 3**: Pub/Sub with agent subscribers
- **Pattern 4**: Command Messages with async pipelines

## ğŸ™ Don't Forget!

- ğŸ‘ Like this video
- ğŸ’¬ Comment your use cases
- ğŸ“¢ Share with your team
- ğŸ”” Subscribe for Pattern 3!

---

**ğŸ”— Resources:**
- [Pipes and Filters Pattern](https://www.enterpriseintegrationpatterns.com/patterns/messaging/PipesAndFilters.html)
- [Azure AI Foundry](https://learn.microsoft.com/azure/ai-studio/)
- [FastAPI Docs](https://fastapi.tiangolo.com/)

**#EnterpriseIntegration #PipesAndFilters #AIAgents #AzureAI #CloudArchitecture**
